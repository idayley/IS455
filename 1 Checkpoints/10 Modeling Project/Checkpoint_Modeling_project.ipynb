{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv6whY1wdUyN"
      },
      "source": [
        "### READ ME\n",
        "\n",
        "Use the code blocks below to answer each question. Only print the output required for each question. Do not edit the comments at the top of each code cell. Otherwise, the auto-grader may misinterpret your results. See Question 0 as an an example of how to complete a task (leave it in your notebook; don't delete it):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LldV48pCdeRB",
        "outputId": "aa44b626-b668-4fe3-d870-f811e40bb480"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "n1V1eFxCdUyQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tweet_id                      0\n",
            "text                          0\n",
            "context_annotations_count     0\n",
            "count_annotations             0\n",
            "count_cashtags                0\n",
            "count_hashtags                0\n",
            "count_mentions                0\n",
            "count_urls                    0\n",
            "created_at_tweet              0\n",
            "lang                          0\n",
            "likes                         0\n",
            "quotes                        0\n",
            "referenced_tweet_count        0\n",
            "replies                       0\n",
            "reply_settings                0\n",
            "retweets                      0\n",
            "source                        0\n",
            "terms                         0\n",
            "username                      0\n",
            "created_at_author             0\n",
            "followers_count               0\n",
            "following_count               0\n",
            "tweet_count                   0\n",
            "listed_count                  0\n",
            "location                     42\n",
            "protected                     0\n",
            "verified                      0\n",
            "media_type                    0\n",
            "height                        0\n",
            "width                         0\n",
            "preview_image_url             0\n",
            "country                       0\n",
            "name_place                    0\n",
            "place_type                    0\n",
            "dtype: int64\n",
            "-------------------------------------------------\n",
            "skewness: 12.193283459209416\n",
            "-------------------------------------------------\n",
            "skewness after log: 1.282185198437661\n",
            "-------------------------------------------------\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>text</th>\n",
              "      <th>context_annotations_count</th>\n",
              "      <th>count_annotations</th>\n",
              "      <th>count_cashtags</th>\n",
              "      <th>count_hashtags</th>\n",
              "      <th>count_mentions</th>\n",
              "      <th>count_urls</th>\n",
              "      <th>created_at_tweet</th>\n",
              "      <th>lang</th>\n",
              "      <th>...</th>\n",
              "      <th>location</th>\n",
              "      <th>protected</th>\n",
              "      <th>verified</th>\n",
              "      <th>media_type</th>\n",
              "      <th>height</th>\n",
              "      <th>width</th>\n",
              "      <th>preview_image_url</th>\n",
              "      <th>country</th>\n",
              "      <th>name_place</th>\n",
              "      <th>place_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1440484799970304000</td>\n",
              "      <td>This was my grandson this morning (w/autism)! ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2021-09-22T01:15:13.000Z</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Victoria,  BC</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>photo</td>\n",
              "      <td>405</td>\n",
              "      <td>813</td>\n",
              "      <td>https://pbs.twimg.com/media/E_2hSs4UcAAIOK5.jpg</td>\n",
              "      <td>Canada</td>\n",
              "      <td>Langford</td>\n",
              "      <td>city</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1439618825171963904</td>\n",
              "      <td>Wow!! Been into #York for the first time since...</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2021-09-19T15:54:09.000Z</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Hessay, York</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>photo</td>\n",
              "      <td>2048</td>\n",
              "      <td>1536</td>\n",
              "      <td>https://pbs.twimg.com/media/E_qNsE1X0AQmoK_.jpg</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>Hessay</td>\n",
              "      <td>city</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1248872872837332992</td>\n",
              "      <td>Sad number of ppl who lost life due to covid-1...</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2020-04-11T07:17:50.000Z</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Maidstone, South East</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>photo</td>\n",
              "      <td>288</td>\n",
              "      <td>278</td>\n",
              "      <td>https://pbs.twimg.com/media/EVTjQcoXsAAlrfq.jpg</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>Maidstone</td>\n",
              "      <td>city</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1250729294051053568</td>\n",
              "      <td>Webinar now available‘Staying healthy at home ...</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2020-04-16T10:14:35.000Z</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Maidstone, South East</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>photo</td>\n",
              "      <td>2048</td>\n",
              "      <td>2048</td>\n",
              "      <td>https://pbs.twimg.com/media/EVt7pYTXkAMGzxj.jpg</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>Maidstone</td>\n",
              "      <td>city</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1249612131433095168</td>\n",
              "      <td>Webinar now available‘Staying healthy at home ...</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2020-04-13T08:15:23.000Z</td>\n",
              "      <td>en</td>\n",
              "      <td>...</td>\n",
              "      <td>Maidstone, South East</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>photo</td>\n",
              "      <td>2048</td>\n",
              "      <td>2048</td>\n",
              "      <td>https://pbs.twimg.com/media/EVeDlp7X0AMuN6X.jpg</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>Maidstone</td>\n",
              "      <td>city</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 34 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              tweet_id                                               text  \\\n",
              "0  1440484799970304000  This was my grandson this morning (w/autism)! ...   \n",
              "1  1439618825171963904  Wow!! Been into #York for the first time since...   \n",
              "2  1248872872837332992  Sad number of ppl who lost life due to covid-1...   \n",
              "3  1250729294051053568  Webinar now available‘Staying healthy at home ...   \n",
              "4  1249612131433095168  Webinar now available‘Staying healthy at home ...   \n",
              "\n",
              "   context_annotations_count  count_annotations  count_cashtags  \\\n",
              "0                          1                0.0             0.0   \n",
              "1                          2                2.0             0.0   \n",
              "2                          3                0.0             0.0   \n",
              "3                          1                2.0             0.0   \n",
              "4                          1                2.0             0.0   \n",
              "\n",
              "   count_hashtags  count_mentions  count_urls          created_at_tweet lang  \\\n",
              "0             0.0             0.0         1.0  2021-09-22T01:15:13.000Z   en   \n",
              "1             3.0             0.0         1.0  2021-09-19T15:54:09.000Z   en   \n",
              "2             0.0             0.0         1.0  2020-04-11T07:17:50.000Z   en   \n",
              "3             3.0             0.0         2.0  2020-04-16T10:14:35.000Z   en   \n",
              "4             3.0             0.0         2.0  2020-04-13T08:15:23.000Z   en   \n",
              "\n",
              "   ...               location  protected  verified  media_type height  width  \\\n",
              "0  ...         Victoria,  BC       False     False       photo    405    813   \n",
              "1  ...           Hessay, York      False     False       photo   2048   1536   \n",
              "2  ...  Maidstone, South East      False     False       photo    288    278   \n",
              "3  ...  Maidstone, South East      False     False       photo   2048   2048   \n",
              "4  ...  Maidstone, South East      False     False       photo   2048   2048   \n",
              "\n",
              "                                 preview_image_url         country name_place  \\\n",
              "0  https://pbs.twimg.com/media/E_2hSs4UcAAIOK5.jpg          Canada   Langford   \n",
              "1  https://pbs.twimg.com/media/E_qNsE1X0AQmoK_.jpg  United Kingdom     Hessay   \n",
              "2  https://pbs.twimg.com/media/EVTjQcoXsAAlrfq.jpg  United Kingdom  Maidstone   \n",
              "3  https://pbs.twimg.com/media/EVt7pYTXkAMGzxj.jpg  United Kingdom  Maidstone   \n",
              "4  https://pbs.twimg.com/media/EVeDlp7X0AMuN6X.jpg  United Kingdom  Maidstone   \n",
              "\n",
              "  place_type  \n",
              "0       city  \n",
              "1       city  \n",
              "2       city  \n",
              "3       city  \n",
              "4       city  \n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Question 1: Import the data here and perform any data cleaning\n",
        "# steps that you feel are necessary in this code cell. Keep all \n",
        "# cleaning steps here in the same code cell. First, check for missing\n",
        "# values and print out the totals. If you have missing values, then\n",
        "# either replace them (.fillna()) with a theoretically meaningful \n",
        "# value (e.g. 'other' or 0) or delete the column. You may delete rows\n",
        "# as long as you can maintain a final row count >= 500.\n",
        "# \n",
        "# Next, check for label skewness and print out the skewness scores. \n",
        "# Make an adjustment to the label if the skewness is > 1 or < -1. If \n",
        "# you cannot get the label between -1 to 1 after making an adjustment, \n",
        "# that is okay for now. It just means that, in practice, you would switch\n",
        "# to using a Decision Trees regression model rather than MLR. \n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#import data set\n",
        "df = pd.read_csv('tw_tweets_users_media_places.csv')\n",
        "\n",
        "#check for missing values\n",
        "print(df.isnull().sum())\n",
        "print('-------------------------------------------------')\n",
        "\n",
        "# fill in missing values in the location column\n",
        "df['location'].fillna('Other', inplace=True)\n",
        "\n",
        "#check for label skewness\n",
        "label = 'likes'\n",
        "print('skewness: ' + str(df[label].skew()))\n",
        "print('-------------------------------------------------')\n",
        "\n",
        "# use natural log to transform the label\n",
        "df[label] = np.log1p(df[label])\n",
        "print('skewness after log: ' + str(df[label].skew()))\n",
        "print('-------------------------------------------------')\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUjC8kPn8du5"
      },
      "source": [
        "## **MLR Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "wAXURAM8dUyR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "starting R Squared 0.12407988932804592\n",
            "Dropping Charleston with a p-value of 0.9903293822261563.\n",
            "Dropping Charleston, SC with a p-value of 0.990329382245585.\n",
            "Dropping Walsall, England with a p-value of 0.8480140284952782.\n",
            "Dropping Willenhall with a p-value of 0.8480140284665199.\n",
            "Dropping Little Rock with a p-value of 0.7933474343543606.\n",
            "Dropping covid%20\"sensory overload\" with a p-value of 0.7933474343457017.\n",
            "Dropping Greenock, Scotland with a p-value of 0.5433148071078586.\n",
            "Dropping Greenock with a p-value of 0.5433148070993097.\n",
            "Dropping corona%20autism with a p-value of 0.41458932708690177.\n",
            "Dropping tweet_count with a p-value of 0.3985844318689902.\n",
            "Dropping Garston with a p-value of 0.40847484599591644.\n",
            "Dropping Nottingham, England with a p-value of 0.40847484687835434.\n",
            "----------------------------------------------\n",
            "Final R squared 0.12294934900754606\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>context_annotations_count</th>\n",
              "      <th>count_annotations</th>\n",
              "      <th>count_cashtags</th>\n",
              "      <th>count_hashtags</th>\n",
              "      <th>count_mentions</th>\n",
              "      <th>count_urls</th>\n",
              "      <th>likes</th>\n",
              "      <th>quotes</th>\n",
              "      <th>referenced_tweet_count</th>\n",
              "      <th>...</th>\n",
              "      <th>Yarm</th>\n",
              "      <th>Yonkers</th>\n",
              "      <th>York Hospital</th>\n",
              "      <th>Zuienkerke</th>\n",
              "      <th>İstanbul</th>\n",
              "      <th>トロン温泉 稲荷湯</th>\n",
              "      <th>city</th>\n",
              "      <th>country</th>\n",
              "      <th>neighborhood</th>\n",
              "      <th>poi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1440484799970304000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.708050</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1439618825171963904</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1248872872837332992</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.912023</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1250729294051053568</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.386294</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1249612131433095168</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.772589</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 665 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              tweet_id  context_annotations_count  count_annotations  \\\n",
              "0  1440484799970304000                          1                0.0   \n",
              "1  1439618825171963904                          2                2.0   \n",
              "2  1248872872837332992                          3                0.0   \n",
              "3  1250729294051053568                          1                2.0   \n",
              "4  1249612131433095168                          1                2.0   \n",
              "\n",
              "   count_cashtags  count_hashtags  count_mentions  count_urls     likes  \\\n",
              "0             0.0             0.0             0.0         1.0  2.708050   \n",
              "1             0.0             3.0             0.0         1.0  2.079442   \n",
              "2             0.0             0.0             0.0         1.0  3.912023   \n",
              "3             0.0             3.0             0.0         2.0  1.386294   \n",
              "4             0.0             3.0             0.0         2.0  2.772589   \n",
              "\n",
              "   quotes  referenced_tweet_count  ...  Yarm  Yonkers  York Hospital  \\\n",
              "0       0                       0  ...     0        0              0   \n",
              "1       0                       0  ...     0        0              0   \n",
              "2       1                       0  ...     0        0              0   \n",
              "3       0                       0  ...     0        0              0   \n",
              "4       2                       0  ...     0        0              0   \n",
              "\n",
              "   Zuienkerke  İstanbul  トロン温泉 稲荷湯  city  country  neighborhood  poi  \n",
              "0           0         0          0     1        0             0    0  \n",
              "1           0         0          0     1        0             0    0  \n",
              "2           0         0          0     1        0             0    0  \n",
              "3           0         0          0     1        0             0    0  \n",
              "4           0         0          0     1        0             0    0  \n",
              "\n",
              "[5 rows x 665 columns]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Question 2: Build an MLR model based on one of the labels you \n",
        "# identified and collected during the Web Scraping Project. Keep \n",
        "# all of the code contained here in this code block. You should \n",
        "# have at least one or more features that need to be dummy coded. \n",
        "# Scale the data using a MinMax normalization. Do not include any\n",
        "# unstructured features such as tweet text, product description, \n",
        "# or image URLs.\n",
        "# \n",
        "# After you have build the first MLR model, trim all of the \n",
        "# insignificant features from the model so that only those \n",
        "# with p-values < 0.20 are included in your model. Yes, that is \n",
        "# higher than the typical 0.05 cutoff. However, if you have only\n",
        "# 500 records, it is not uncommon to accept higher p-values. You\n",
        "# do not need to split the data for this model if you are using the\n",
        "# statsmodels.api package as we do in the book. Although you\n",
        "# normally would in practice.\n",
        "import statsmodels.api as sm\n",
        "from sklearn import preprocessing\n",
        "\n",
        "df_dummies = df.copy()\n",
        "\n",
        "#drop tweet text, image urls\n",
        "df_dummies.drop(columns=['text', 'created_at_tweet', 'preview_image_url', 'username', 'created_at_author'], inplace=True)\n",
        "\n",
        "#drop alternative labels\n",
        "df_dummies.drop(columns=['retweets', 'replies'], inplace=True)\n",
        "\n",
        "#make dummy codes\n",
        "for col in df_dummies:\n",
        "  if not pd.api.types.is_numeric_dtype(df_dummies[col]):\n",
        "    df_dummies = pd.get_dummies(df_dummies, columns=[col], drop_first=True, prefix=\"\", prefix_sep=\"\")\n",
        "  \n",
        "\n",
        "#standardize the data\n",
        "df_minmax = pd.DataFrame(preprocessing.MinMaxScaler().fit_transform(df_dummies), columns=df_dummies.columns)\n",
        "\n",
        "#run the MLR\n",
        "def mlr():\n",
        "  y = df_dummies[label]\n",
        "  X = df_dummies.drop(columns=label).assign(const=1)\n",
        "  results = sm.OLS(y, X.astype(float)).fit()\n",
        "  return results\n",
        "results = mlr()\n",
        "# print(results.summary())\n",
        "\n",
        "print(f'starting R Squared {results.rsquared}')\n",
        "while (abs(results.pvalues.sort_values(ascending=False)[0]) > 0.20):\n",
        "    # get the highest p-value column\n",
        "    highestCol = (results.pvalues.sort_values(ascending=False)).index[0]\n",
        "    print(f'Dropping {highestCol} with a p-value of {(results.pvalues.sort_values(ascending=False))[0]}.')\n",
        "    df_dummies.drop(columns=[highestCol], inplace=True)\n",
        "    # re-run the model\n",
        "    y = df_dummies[label]\n",
        "    X = df_dummies.drop(columns=[label]).assign(const=1)\n",
        "    model = sm.OLS(y, X.astype(float))\n",
        "    results = model.fit()\n",
        "print(\"----------------------------------------------\")\n",
        "print(f'Final R squared {results.rsquared}')\n",
        "df_dummies.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRd8Jixj8ToW"
      },
      "source": [
        "## **Decision Tree Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "FgwbzbRmdUyS"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>527</th>\n",
              "      <td>quarantine%20neurotypical</td>\n",
              "      <td>quarantine%20neurotypical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>quarantine%20autistic</td>\n",
              "      <td>quarantine%20autistic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>quarantine%20autistic</td>\n",
              "      <td>quarantine%20autistic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>quarantine%20autistic</td>\n",
              "      <td>quarantine%20autistic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>quarantine%20autistic</td>\n",
              "      <td>quarantine%20autistic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Actual                  Predicted\n",
              "527  quarantine%20neurotypical  quarantine%20neurotypical\n",
              "267      quarantine%20autistic      quarantine%20autistic\n",
              "268      quarantine%20autistic      quarantine%20autistic\n",
              "269      quarantine%20autistic      quarantine%20autistic\n",
              "459      quarantine%20autistic      quarantine%20autistic"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Question 3: Build a Decision Tree model based on one of the categorical\n",
        "# labels you identified and collected during the Web Scraping Project. Keep \n",
        "# all of the code contained here in this code block. \n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_decision_tree = df_dummies.copy()\n",
        "\n",
        "#set y and X\n",
        "y = df['terms']                       #Not sure if this is the right thing to be predicting\n",
        "X = df_decision_tree.drop(columns=label)\n",
        "\n",
        "#train the decision tree model\n",
        "clf = DecisionTreeClassifier()\n",
        "clf = clf.fit(X, y)\n",
        "\n",
        "#make a prediction using the decision tree model\n",
        "y_pred = clf.predict(X)\n",
        "pd.DataFrame({'Actual': y, 'Predicted': y_pred}).sort_values(by=['Actual', 'Predicted'], ascending=[False, True]).head(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "U29746C-1WQ-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in c:\\users\\jackson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\jackson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from sklearn) (0.23.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\jackson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->sklearn) (1.19.2)\n",
            "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\jackson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->sklearn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\jackson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in c:\\users\\jackson\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from scikit-learn->sklearn) (0.17.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
            "You should consider upgrading via the 'c:\\users\\jackson\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sklearn.externals.six'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28660/1793567169.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msix\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mdot_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn.externals.six'"
          ]
        }
      ],
      "source": [
        "# Question 4: Create a visualization of the Decision Tree model so that\n",
        "# you can interpret the results\n",
        "\n",
        "#visualize the tree\n",
        "from sklearn.tree import export_graphviz\n",
        "from IPython.display import Image  \n",
        "import pydotplus, six\n",
        "from sklearn.externals.six import StringIO\n",
        "\n",
        "dot_data = StringIO()\n",
        "export_graphviz(clf, out_file=dot_data, filled=True, rounded=True, special_characters=True, feature_names = X.columns,class_names=['no', 'yes'])\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "graph.write_png('protected.png')\n",
        "Image(graph.create_png())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsaL9eMn1WQ_"
      },
      "source": [
        "## **Cluster Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8i8wt4aJ1WRA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0    533\n",
            "1      1\n",
            "Name: cluster, dtype: int64\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>context_annotations_count</th>\n",
              "      <th>count_annotations</th>\n",
              "      <th>count_cashtags</th>\n",
              "      <th>count_hashtags</th>\n",
              "      <th>count_mentions</th>\n",
              "      <th>count_urls</th>\n",
              "      <th>likes</th>\n",
              "      <th>quotes</th>\n",
              "      <th>referenced_tweet_count</th>\n",
              "      <th>...</th>\n",
              "      <th>Yonkers</th>\n",
              "      <th>York Hospital</th>\n",
              "      <th>Zuienkerke</th>\n",
              "      <th>İstanbul</th>\n",
              "      <th>トロン温泉 稲荷湯</th>\n",
              "      <th>city</th>\n",
              "      <th>country</th>\n",
              "      <th>neighborhood</th>\n",
              "      <th>poi</th>\n",
              "      <th>cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1440484799970304000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.708050</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1439618825171963904</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.079442</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1248872872837332992</td>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.912023</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1250729294051053568</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.386294</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1249612131433095168</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.772589</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 666 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              tweet_id  context_annotations_count  count_annotations  \\\n",
              "0  1440484799970304000                          1                0.0   \n",
              "1  1439618825171963904                          2                2.0   \n",
              "2  1248872872837332992                          3                0.0   \n",
              "3  1250729294051053568                          1                2.0   \n",
              "4  1249612131433095168                          1                2.0   \n",
              "\n",
              "   count_cashtags  count_hashtags  count_mentions  count_urls     likes  \\\n",
              "0             0.0             0.0             0.0         1.0  2.708050   \n",
              "1             0.0             3.0             0.0         1.0  2.079442   \n",
              "2             0.0             0.0             0.0         1.0  3.912023   \n",
              "3             0.0             3.0             0.0         2.0  1.386294   \n",
              "4             0.0             3.0             0.0         2.0  2.772589   \n",
              "\n",
              "   quotes  referenced_tweet_count  ...  Yonkers  York Hospital  Zuienkerke  \\\n",
              "0       0                       0  ...        0              0           0   \n",
              "1       0                       0  ...        0              0           0   \n",
              "2       1                       0  ...        0              0           0   \n",
              "3       0                       0  ...        0              0           0   \n",
              "4       2                       0  ...        0              0           0   \n",
              "\n",
              "   İstanbul  トロン温泉 稲荷湯  city  country  neighborhood  poi  cluster  \n",
              "0         0          0     1        0             0    0        0  \n",
              "1         0          0     1        0             0    0        0  \n",
              "2         0          0     1        0             0    0        0  \n",
              "3         0          0     1        0             0    0        0  \n",
              "4         0          0     1        0             0    0        0  \n",
              "\n",
              "[5 rows x 666 columns]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Question 5: Build a cluster model using either K-means or Agglomerative\n",
        "# clustering based on which you think is best for your data type. Remember,\n",
        "# k-means is best when the data types and scales are uniform and\n",
        "# agglomerative is best when both are mixed. If you used k-means, then\n",
        "# calculate all three metrics for determining the optimal number of clusters.\n",
        "# If you use agglomerative clustering, use the Gower matrix as the distance\n",
        "# measure. With either clustering algorithm, print out a value_counts() of the \n",
        "# number of cases in each cluster. Keep all code in this code cell. \n",
        "\n",
        "import gower\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "distance_matrix = gower.gower_matrix(df_decision_tree)\n",
        "agg = AgglomerativeClustering(affinity='precomputed', linkage='average').fit(distance_matrix)\n",
        "\n",
        "#make a cluster column\n",
        "df_wcluster = df_decision_tree.copy()\n",
        "df_wcluster['cluster'] = agg.labels_\n",
        "print(df_wcluster.cluster.value_counts())\n",
        "df_wcluster.head()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Checkpoint_Modeling_project.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "f8ec8e2802e9ec64c1de1126b52a3a3eba2bbbc7f0465a520b33d3486dfa46c4"
    },
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
